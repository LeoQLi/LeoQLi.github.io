<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content=" ">
  <meta name="keywords" content=" ">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VA-GS</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());
    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="../static/style.css">
  <link rel="stylesheet" href="../static/css/bulma.min.css">
  <link rel="stylesheet" href="../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="../static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="../static/js/fontawesome.all.min.js"></script>
  <script src="../static/js/bulma-carousel.min.js"></script>
  <script src="../static/js/bulma-slider.min.js"></script>
  <script src="../static/js/index.js"></script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.7.7/MathJax.js?config=AM_HTMLorMML-full"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    });
  </script>
</head>

<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://LeoQLi.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>

<section class="hero" style="margin-top: -30px">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment</h1>
          <div class="column is-full_width">
            <h2 class="title is-4">NeurIPS 2025</h2>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://leoqli.github.io/">Qing Li</a><sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              Huifang Feng<sup>2</sup>
            </span>&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://faculty.swjtu.edu.cn/gongxun/zh_CN/index.htm">Xun Gong</a><sup>1</sup>
            </span>&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://yushen-liu.github.io/">Yu-Shen Liu</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>Southwest Jiaotong University,</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Xihua University,</span>&nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>Tsinghua University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.11473"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/LeoQLi/VA-GS"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -50px">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D Gaussian Splatting has recently emerged as an efficient solution for high-quality and real-time novel view synthesis. However, its capability for accurate surface reconstruction remains underexplored. Due to the discrete and unstructured nature of Gaussians, supervision based solely on image rendering loss often leads to inaccurate geometry and inconsistent multi-view alignment. In this work, we propose a novel method that enhances the geometric representation of 3D Gaussians through view alignment (VA). Specifically, we incorporate edge-aware image cues into the rendering loss to improve surface boundary delineation. To enforce geometric consistency across views, we introduce a visibility-aware photometric alignment loss that models occlusions and encourages accurate spatial relationships among Gaussians. To further mitigate ambiguities caused by lighting variations, we incorporate normal-based constraints to refine the spatial orientation of Gaussians and improve local surface estimation. Additionally, we leverage deep image feature embeddings to enforce cross-view consistency, enhancing the robustness of the learned geometry under varying viewpoints and illumination. Extensive experiments on standard benchmarks demonstrate that our method achieves state-of-the-art performance in both surface reconstruction and novel view synthesis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -50px">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Method</h2>

        <div style="text-align: center;">
          <img src="./images/VA-GS.jpg" class="center" width="90%">
        </div>
        <!-- <p style="font-size: large;"> -->
          <!-- <b>
            Overview of our method.
          </b> -->
            <!-- The training includes five loss functions: $\mathcal{L}_{I}$, $\mathcal{L}_{nc}$, $\mathcal{L}_{ns}$, $\mathcal{L}_{p}$ and $\mathcal{L}_{f}$.
            The occlusion weight $\omega$, visibility item $\upsilon$ and homography matrix $\bm{H}$ are involved in $\mathcal{L}_{p}$ and $\mathcal{L}_{f}$.
            The image features $\bm{F}_s$ and $\bm{F}_r$ are extracted using a pretrained network $f$.
            $\{\bm{K}, \bm{M}\}$ is the intrinsic/extrinsic parameter matrix of the camera view. -->
            <!-- The training includes five loss functions:
            <math><mi>ùìõ</mi><sub><mi>I</mi></sub></math>,
            <math><mi>ùìõ</mi><sub><mi>nc</mi></sub></math>,
            <math><mi>ùìõ</mi><sub><mi>ns</mi></sub></math>,
            <math><mi>ùìõ</mi><sub><mi>p</mi></sub></math>
            and
            <math><mi>ùìõ</mi><sub><mi>f</mi></sub></math>.
            The occlusion weight
            <math><mi>œâ</mi></math>,
            visibility item
            <math><mi>œÖ</mi></math>
            and homography matrix
            <math><b><mi>H</mi></b></math>
            are involved in
            <math><mi>ùìõ</mi><sub><mi>p</mi></sub></math>
            and
            <math><mi>ùìõ</mi><sub><mi>f</mi></sub></math>.
            The image features
            <math><b><mi>F</mi></b><sub><mi>s</mi></sub></math>
            and
            <math><b><mi>F</mi></b><sub><mi>r</mi></sub></math>
            are extracted using a pretrained network
            <math><mi>f</mi></math>.
            <math>
              <mo>{</mo>
              <b><mi>K</mi></b>,
              <b><mi>M</mi></b>
              <mo>}</mo>
            </math>
            is the intrinsic/extrinsic parameter matrix of the camera view. -->
        <!-- </p> -->
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -50px">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Results</h2>

        <!-- <h3 class="title is-5" style="margin-top: 30px;">Normal RMSE</h3> -->
        <img src="./images/vis_tnt.jpg" class="center" style="margin-top: 0px" width="90%">
        <!-- <p style="font-size: large;">
          Visual comparison of oriented normals on two point clouds with complex geometry. Colors indicate normal errors.
        </p> -->

        <!-- <h3 class="title is-5" style="margin-top: 30px;">Surface Reconstruction</h3> -->
        <img src="./images/vis_360.jpg" class="center" style="margin-top: 20px" width="90%">
        <!-- <p style="font-size: large;">
          Visual comparison of reconstructed surfaces. As the noise increases (from low to high), our method becomes more advantageous.
        </p> -->

        <img src="./images/tab_dtu.jpg" class="center" style="margin-top: 50px" width="85%">

        <img src="./images/tab_tnt.jpg" class="center" style="margin-top: 0px" width="80%">

        <img src="./images/tab_360.jpg" class="center" style="margin-top: 0px" width="80%">
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX" style="margin-top: -50px">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre>
      <code>
  @inproceedings{li2025vags,
    title={{VA-GS}: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment},
    author={Li, Qing and Feng, Huifang and Gong, Xun and Liu, Yu-Shen},
    booktitle={Thirty-Ninth Conference on Neural Information Processing Systems (NeurIPS)},
    year={2025}
  }
      </code>
    </pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <p>
        This webpage template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>
